{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.utils import shuffle # library to shuffle the dataframes\n",
    "import seaborn as sns # library to plot and visualize data\n",
    "from sklearn.model_selection import train_test_split # library to split data into trining and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the datatype of each column for reading the CSV file\n",
    "dataTypes = {\n",
    "    \"UniqueID\": np.uint16,\n",
    "    \"disbursed_amount\": np.float64,\n",
    "    \"asset_cost\": np.float64,\n",
    "    \"ltv\": np.float64,\n",
    "    \"branch_id\": np.object,\n",
    "    \"supplier_id\": np.object,\n",
    "    \"manufacturer_id\": np.object,\n",
    "    \"Current_pincode_ID\": np.object,\n",
    "    \"Date.of.Birth\": np.object,\n",
    "    \"Employment.Type\": np.object,\n",
    "    \"DisbursalDate\": np.object,\n",
    "    \"State_ID\": np.object,\n",
    "    \"Employee_code_ID\": np.object,\n",
    "    \"MobileNo_Avl_Flag\": np.uint8,\n",
    "    \"Aadhar_flag\": np.uint8,\n",
    "    \"PAN_flag\": np.uint8,\n",
    "    \"VoterID_flag\": np.uint8,\n",
    "    \"Driving_flag\": np.uint8,\n",
    "    \"Passport_flag\": np.uint8,\n",
    "    \"PERFORM_CNS.SCORE\": np.uint16,\n",
    "    \"PERFORM_CNS.SCORE.DESCRIPTION\": np.object,\n",
    "    \"PRI.NO.OF.ACCTS\": np.uint8,\n",
    "    \"PRI.ACTIVE.ACCTS\": np.uint8,\n",
    "    \"PRI.OVERDUE.ACCTS\": np.uint8,\n",
    "    \"PRI.CURRENT.BALANCE\": np.float64,\n",
    "    \"PRI.SANCTIONED.AMOUNT\": np.float64,\n",
    "    \"PRI.DISBURSED.AMOUNT\": np.float64,\n",
    "    \"SEC.NO.OF.ACCTS\": np.uint8,\n",
    "    \"SEC.ACTIVE.ACCTS\": np.uint8,\n",
    "    \"SEC.OVERDUE.ACCTS\": np.uint8,\n",
    "    \"SEC.CURRENT.BALANCE\": np.float64,\n",
    "    \"SEC.SANCTIONED.AMOUNT\": np.float64,\n",
    "    \"SEC.DISBURSED.AMOUNT\": np.float64,\n",
    "    \"PRIMARY.INSTAL.AMT\": np.float64,\n",
    "    \"SEC.INSTAL.AMT\": np.float64,\n",
    "    \"NEW.ACCTS.IN.LAST.SIX.MONTHS\": np.uint8,\n",
    "    \"DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS\": np.uint8,\n",
    "    \"AVERAGE.ACCT.AGE\": np.object,\n",
    "    \"CREDIT.HISTORY.LENGTH\": np.object,\n",
    "    \"NO.OF_INQUIRIES\": np.uint8,\n",
    "    \"loan_default\": np.uint8\n",
    "}\n",
    "\n",
    "# Input data files are available in the \"../data/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "trainRaw = pd.read_csv(\"data/train.csv\", dtype=dataTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToDrop = {\n",
    "    \"UniqueID\",\n",
    "    \"Date.of.Birth\",\n",
    "    \"DisbursalDate\",\n",
    "    \"PERFORM_CNS.SCORE\",\n",
    "    \"PERFORM_CNS.SCORE.DESCRIPTION\",\n",
    "    'Employment.Type',\n",
    "    #\"supplier_id\",\n",
    "    #'branch_id',\n",
    "    #'manufacturer_id',\n",
    "    #'Current_pincode_ID',\n",
    "    #'State_ID',\n",
    "    #'Employee_code_ID',\n",
    "    'MobileNo_Avl_Flag',\n",
    "    \"PAN_flag\",\n",
    "    \"Driving_flag\",\n",
    "    'Passport_flag',\n",
    "    'SEC.OVERDUE.ACCTS',\n",
    "    'SEC.ACTIVE.ACCTS',\n",
    "    'SEC.INSTAL.AMT',\n",
    "    \"SEC.INSTAL.AMT\",\n",
    "    \"SEC.CURRENT.BALANCE\",\n",
    "    'SEC.SANCTIONED.AMOUNT',\n",
    "    'SEC.DISBURSED.AMOUNT',\n",
    "    'SEC.NO.OF.ACCTS'\n",
    "}\n",
    "\n",
    "def parseDuration(x):\n",
    "    x_yrs = x.split()[0]\n",
    "    x_mon = x.split()[1]\n",
    "    n_years = x_yrs[:(len(x_yrs)-3)]\n",
    "    n_mon = x_mon[:(len(x_mon)-3)]\n",
    "    return int(n_years) * 12 + int(n_mon)\n",
    "\n",
    "def parseDate(v):\n",
    "    if v.split(\"-\")[-1]=='00' or v.split(\"-\")[-1]=='18':\n",
    "        return \"-\".join(v.split(\"-\")[:-1])+'-20'+\"\".join(v.split(\"-\")[-1])\n",
    "    else:\n",
    "        return \"-\".join(v.split(\"-\")[:-1])+'-19'+\"\".join(v.split(\"-\")[-1])\n",
    "    \n",
    "def getScoreGrade(desc):\n",
    "    grade = desc.split(\"-\")\n",
    "    if len(grade) != 1:\n",
    "        return grade[0]\n",
    "    else:\n",
    "        return 'Z'\n",
    "\n",
    "#Pre-Process the data\n",
    "def removeOutliers(data):\n",
    "    data['disbursed_amount'] = np.clip(data['disbursed_amount'], a_min=25000, a_max = 80000)\n",
    "    data['asset_cost'] = np.clip(data['asset_cost'], a_min=45000, a_max = 100000)\n",
    "    data['ltv'] = np.clip(data['ltv'], a_min=40, a_max = 100)\n",
    "    data['PRI.NO.OF.ACCTS'] = np.clip(data['PRI.NO.OF.ACCTS'], a_min=0, a_max = 10)\n",
    "    data['PRI.ACTIVE.ACCTS'] = np.clip(data['PRI.ACTIVE.ACCTS'], a_min=0, a_max = 10)\n",
    "    data['PRI.OVERDUE.ACCTS'] = np.clip(data['PRI.OVERDUE.ACCTS'], a_min=0, a_max = 5)\n",
    "    data['PRI.CURRENT.BALANCE'] = np.clip(data['PRI.CURRENT.BALANCE'], a_min=0, a_max = 500000)\n",
    "    data['PRI.SANCTIONED.AMOUNT'] = np.clip(data['PRI.SANCTIONED.AMOUNT'], a_min=0, a_max = 500000)\n",
    "    data['PRI.DISBURSED.AMOUNT'] = np.clip(data['PRI.DISBURSED.AMOUNT'], a_min=0, a_max = 500000)\n",
    "    data['SEC.NO.OF.ACCTS'] = np.clip(data['SEC.NO.OF.ACCTS'], a_min=0, a_max = 5)\n",
    "    data['SEC.ACTIVE.ACCTS'] = np.clip(data['SEC.ACTIVE.ACCTS'], a_min=0, a_max = 3)\n",
    "    data['SEC.OVERDUE.ACCTS'] = np.clip(data['SEC.OVERDUE.ACCTS'], a_min=0, a_max = 1)\n",
    "    data['SEC.CURRENT.BALANCE'] = np.clip(data['SEC.CURRENT.BALANCE'], a_min=0, a_max = 100000)\n",
    "    data['SEC.SANCTIONED.AMOUNT'] = np.clip(data['SEC.SANCTIONED.AMOUNT'], a_min=0, a_max = 100000)\n",
    "    data['SEC.DISBURSED.AMOUNT'] = np.clip(data['SEC.DISBURSED.AMOUNT'], a_min=0, a_max = 100000)\n",
    "    data['PRIMARY.INSTAL.AMT'] = np.clip(data['PRIMARY.INSTAL.AMT'], a_min=0, a_max = 10000)\n",
    "    data['SEC.INSTAL.AMT'] = np.clip(data['SEC.INSTAL.AMT'], a_min=0, a_max = 2000)\n",
    "    data['NEW.ACCTS.IN.LAST.SIX.MONTHS'] = np.clip(data['NEW.ACCTS.IN.LAST.SIX.MONTHS'], a_min=0, a_max = 4)\n",
    "    data['DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS'] = np.clip(data['DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS'], a_min=0, a_max = 5)\n",
    "    data['AVERAGE.ACCT.AGE'] = np.clip(data['AVERAGE.ACCT.AGE'], a_min=0, a_max = 48)\n",
    "    data['CREDIT.HISTORY.LENGTH'] = np.clip(data['CREDIT.HISTORY.LENGTH'], a_min=0, a_max = 120)\n",
    "    data['NO.OF_INQUIRIES'] = np.clip(data['NO.OF_INQUIRIES'], a_min=0, a_max = 20)\n",
    "\n",
    "#Pre-Process the data\n",
    "def preProcessData(raw):\n",
    "    data = raw.copy()\n",
    "    \n",
    "    data['Date.of.Birth'] = pd.to_datetime(data['Date.of.Birth'].apply(parseDate), format='%d-%m-%Y', errors='coerce')\n",
    "    data['DisbursalDate'] = pd.to_datetime(data['DisbursalDate'].apply(parseDate), format='%d-%m-%Y')\n",
    "    data['AgeAtDisbursal'] = (data['DisbursalDate'] - data['Date.of.Birth']).astype('<m8[Y]')\n",
    "    \n",
    "    data['Employment.Type'].fillna('Other', inplace=True)\n",
    "    \n",
    "    data['AVERAGE.ACCT.AGE'] = data['AVERAGE.ACCT.AGE'].apply(parseDuration)\n",
    "    data['CREDIT.HISTORY.LENGTH'] = data['CREDIT.HISTORY.LENGTH'].apply(parseDuration)\n",
    "    \n",
    "    removeOutliers(data)\n",
    "    \n",
    "    data['Sanctioned'] = (data['asset_cost'] * (data['ltv'] / 100)).astype(np.float64)\n",
    "    data['TOTAL.ACTIVE.ACCTS'] = (data['PRI.ACTIVE.ACCTS'] + data['SEC.ACTIVE.ACCTS']).astype(np.int64)\n",
    "    data['TOTAL.CURRENT.BALANCE'] = (data['PRI.CURRENT.BALANCE'] + data['SEC.CURRENT.BALANCE']).astype(np.float64)\n",
    "    data['TOTAL.DISBURSED.AMOUNT'] = (data['PRI.DISBURSED.AMOUNT'] + data['SEC.DISBURSED.AMOUNT']).astype(np.int64)\n",
    "    data['TOTAL.NO.OF.ACCTS'] = (data['PRI.NO.OF.ACCTS'] + data['SEC.NO.OF.ACCTS']).astype(np.int64)\n",
    "    data['TOTAL.OVERDUE.ACCTS'] = (data['PRI.OVERDUE.ACCTS'] + data['SEC.OVERDUE.ACCTS']).astype(np.int64)\n",
    "    data['TOTAL.CLEAN.ACCTS'] = (data['TOTAL.NO.OF.ACCTS'] - data['TOTAL.OVERDUE.ACCTS']).astype(np.int64)\n",
    "    data['NO.OF.ACC.BF.SIX.MONTH'] = (data['TOTAL.NO.OF.ACCTS'] - data['NEW.ACCTS.IN.LAST.SIX.MONTHS']).astype(np.int64)\n",
    "    data['OVERDUE.ACC.BF.SIX.MONTHS'] = (data['TOTAL.OVERDUE.ACCTS'] - data['DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS']).astype(np.int64)\n",
    "    data['TOTAL.DEACTIVE.ACCTS'] = (data['TOTAL.NO.OF.ACCTS'] - data['TOTAL.ACTIVE.ACCTS']).astype(np.int64)\n",
    "    data['TOTAL.INSTL.AMOUNT'] = (data['PRIMARY.INSTAL.AMT'] + data['SEC.INSTAL.AMT']).astype(np.float64)\n",
    "    data['TOTAL.CLEARED.ACCTS']= (data['TOTAL.NO.OF.ACCTS'] - data['TOTAL.ACTIVE.ACCTS'] + data['TOTAL.OVERDUE.ACCTS']).astype(np.int64)\n",
    "\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'].replace({\n",
    "        'A-Very Low Risk':'Medium Risk',\n",
    "        'B-Very Low Risk':'Low Risk',\n",
    "        'C-Very Low Risk':'Medium Risk',\n",
    "        'D-Very Low Risk':'Low Risk',\n",
    "        'E-Low Risk':'Medium Risk',\n",
    "        'F-Low Risk':'Medium Risk',\n",
    "        'G-Low Risk':'Medium Risk',\n",
    "        'H-Medium Risk':'High Risk',\n",
    "        'I-Medium Risk':'High Risk',\n",
    "        'J-High Risk':'High Risk',\n",
    "        'K-High Risk':'Very HRisk',\n",
    "        'L-Very High Risk':'Very HRisk',\n",
    "        'M-Very High Risk':'Very HRisk',\n",
    "        'Not Scored: More than 50 active Accounts found':'Low Risk',\n",
    "        'No Bureau History Available':'Medium Risk', \n",
    "        'Not Scored: Only a Guarantor':'High Risk',\n",
    "        'Not Scored: Only a Guarantor':'High Risk',        \n",
    "        'Not Scored: No Activity seen on the customer (Inactive)':'Medium Risk',\n",
    "        'Not Scored: No Updates available in last 36 months':'Medium Risk',\n",
    "        'Not Scored: Not Enough Info available on the customer':'Medium Risk',        \n",
    "        'Not Scored: Sufficient History Not Available':'Very HRisk'}, inplace=True)\n",
    "    \n",
    "    data['Low_Risk'] = np.where(data['PERFORM_CNS.SCORE.DESCRIPTION'].str.contains('Low Risk'), 1, 0)\n",
    "    data['Medium_Risk'] = np.where(data['PERFORM_CNS.SCORE.DESCRIPTION'].str.contains('Medium Risk'), 1, 0)\n",
    "    data['High_Risk'] = np.where(data['PERFORM_CNS.SCORE.DESCRIPTION'].str.contains('High Risk'), 1, 0)\n",
    "    data['Very_High_Risk'] = np.where(data['PERFORM_CNS.SCORE.DESCRIPTION'].str.contains('Very HRisk'), 1, 0)\n",
    "    \n",
    "    X = pd.get_dummies(data[\"Employment.Type\"], prefix=\"Employment.Type\", drop_first=False, dtype=np.uint8)\n",
    "    data = pd.concat([data, X], axis=1)\n",
    "\n",
    "    index = 0\n",
    "    prev = 0\n",
    "    for i in range(100, 1001, 100):\n",
    "        data.loc[(data['PERFORM_CNS.SCORE'] < i) & (data['PERFORM_CNS.SCORE'] >= prev), 'PERFORM_CNS.SCORE'] = index\n",
    "        index = index + 1\n",
    "        prev = i\n",
    "        \n",
    "    X = pd.get_dummies(data[\"PERFORM_CNS.SCORE\"], prefix=\"PERFORM_CNS.SCORE\", drop_first=False, dtype=np.uint8)\n",
    "    data = pd.concat([data, X], axis=1)\n",
    "    \n",
    "    data = data.drop(columnsToDrop, axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preProcessData(trainRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('loan_default', 1)\n",
    "y = train['loan_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"data\\X_train.csv\", sep=',', encoding='utf-8', index=False, header=True)\n",
    "X_test.to_csv(\"data\\X_test.csv\", sep=',', encoding='utf-8', index=False, header=True)\n",
    "y_train.to_csv(\"data\\y_train.csv\", sep=',', encoding='utf-8', index=False, header=True)\n",
    "y_test.to_csv(\"data\\y_test.csv\", sep=',', encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
